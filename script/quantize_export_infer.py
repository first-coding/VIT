import torch
import torch.nn as nn
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import torch.onnx
import onnx
import onnxruntime as ort
import numpy as np
from onnxruntime.quantization import quantize_static, CalibrationDataReader, QuantType

from models.Student import StudentCNN  # ä¿®æ”¹ä¸ºä½ çš„å­¦ç”Ÿæ¨¡å‹è·¯å¾„

# ====== æ•°æ®åŠ è½½ ======
def get_dataloaders():
    transform = transforms.Compose([
        transforms.Resize((32, 32)),
        transforms.ToTensor(),
    ])
    calib_loader = DataLoader(datasets.CIFAR10(root='./data', train=True, download=False, transform=transform), batch_size=32, shuffle=False)
    test_loader = DataLoader(datasets.CIFAR10(root='./data', train=False, download=False, transform=transform), batch_size=32, shuffle=False)
    return calib_loader, test_loader

# ====== ç²¾åº¦è¯„ä¼° ======
def evaluate(model, dataloader):
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for imgs, labels in dataloader:
            out = model(imgs)
            pred = out.argmax(dim=1)
            correct += (pred == labels).sum().item()
            total += labels.size(0)
    return correct / total

# ====== å¯¼å‡º ONNX ======
def export_onnx(model, path="./Output/Onnx/student_cnn.onnx"):
    dummy_input = torch.randn(1, 3, 32, 32)
    torch.onnx.export(
        model,
        dummy_input,
        path,
        input_names=["input"],
        output_names=["output"],
        opset_version=11,
        do_constant_folding=True,
        dynamic_axes={"input": {0: "batch_size"}, "output": {0: "batch_size"}}
    )
    onnx_model = onnx.load(path)
    onnx.checker.check_model(onnx_model)
    print(f"âœ… ONNX æ¨¡å‹å·²å¯¼å‡ºå¹¶éªŒè¯æˆåŠŸï¼š{path}")

# ====== ONNXRuntime æ¨ç† ======
def run_onnx_inference(onnx_path, dataloader):
    # Session Options é…ç½®
    so = ort.SessionOptions()
    so.intra_op_num_threads = 4         # å•ä¸ªæ“ä½œä½¿ç”¨çš„çº¿ç¨‹æ•°
    so.inter_op_num_threads = 2         # å¹¶è¡Œæ“ä½œé—´ä½¿ç”¨çš„çº¿ç¨‹æ•°
    so.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL  # å¯ç”¨æ‰€æœ‰å›¾ä¼˜åŒ–

    # ä½¿ç”¨ CUDA æˆ– CPU æ‰§è¡Œ
    providers = ['CUDAExecutionProvider'] if ort.get_device() == 'GPU' else ['CPUExecutionProvider']
    session = ort.InferenceSession("Output/Onnx/student_cnn.onnx", sess_options=so, providers=providers)
    input_name = session.get_inputs()[0].name
    output_name = session.get_outputs()[0].name

    correct, total = 0, 0
    for images, labels in dataloader:
        images_np = images.numpy().astype(np.float32)
        outputs = session.run([output_name], {input_name: images_np})[0]
        preds = np.argmax(outputs, axis=1)
        correct += (preds == labels.numpy()).sum()
        total += labels.size(0)

    acc = correct / total
    print(f"âœ… ONNX æ¨ç†ç²¾åº¦: {acc * 100:.2f}%")

# ====== æ•°æ®é¢„å¤„ç†ç±» ======
class CIFAR10DataReader(CalibrationDataReader):
    def __init__(self, dataloader):
        self.dataloader = dataloader
        self.data_iter = iter(dataloader)

    def get_next(self):
        try:
            images, _ = next(self.data_iter)
            return {'input': images.numpy()}
        except StopIteration:
            return None

# ====== ä¸»æµç¨‹ ======
def quantize():
    print("ğŸš€ åŠ è½½æ¨¡å‹...")
    model = StudentCNN(num_classes=10)
    model.load_state_dict(torch.load("Output/student/best_student_cnn.pth", map_location='cpu'))
    model.eval()

    calib_loader, test_loader = get_dataloaders()

    print("ğŸ“¦ å¯¼å‡º ONNX æ¨¡å‹...")
    export_onnx(model)

    print("ğŸ“ å¼€å§‹ä½¿ç”¨ ONNXRuntime è¿›è¡Œé™æ€é‡åŒ–...")
    calib_reader = CIFAR10DataReader(calib_loader)
    
    # æ‰§è¡Œé‡åŒ–
    quantize_static(
        model_input="./Output/Onnx/student_cnn.onnx",
        model_output="./Output/Onnx/student_cnn_int8.onnx",
        calibration_data_reader=calib_reader,
        quant_format="QOperator",   # ä½¿ç”¨ QOperator æ ¼å¼
        activation_type=QuantType.QUInt8,
        weight_type=QuantType.QInt8
    )
    print("ğŸ¯ ONNX æ¨¡å‹é‡åŒ–å®Œæˆï¼")

    print("ğŸ¯ é‡åŒ–æ¨¡å‹ç²¾åº¦æµ‹è¯•...")
    run_onnx_inference("./Output/Onnx/student_cnn_int8.onnx", test_loader)
    print("ğŸ é‡åŒ– + å¯¼å‡º + æ¨ç† å®Œæˆï¼")
